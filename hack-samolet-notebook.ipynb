{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8616406,"sourceType":"datasetVersion","datasetId":5157177}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate --quiet","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:20:02.319669Z","iopub.execute_input":"2024-06-16T13:20:02.320552Z","iopub.status.idle":"2024-06-16T13:20:17.446926Z","shell.execute_reply.started":"2024-06-16T13:20:02.320516Z","shell.execute_reply":"2024-06-16T13:20:17.445819Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import datasets\nimport numpy as np\nfrom transformers import BertTokenizerFast\nfrom transformers import DataCollatorForTokenClassification\nfrom transformers import AutoModelForTokenClassification\nfrom transformers import AutoTokenizer\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport ast\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:20:46.728011Z","iopub.execute_input":"2024-06-16T13:20:46.728429Z","iopub.status.idle":"2024-06-16T13:21:05.921309Z","shell.execute_reply.started":"2024-06-16T13:20:46.728394Z","shell.execute_reply":"2024-06-16T13:21:05.920295Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-16 13:20:55.039995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-16 13:20:55.040151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-16 13:20:55.165585: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hack-samolet/train_data.csv')\ndf_nofull = df[df.target_labels_positions != '{}']","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:05.923042Z","iopub.execute_input":"2024-06-16T13:21:05.923651Z","iopub.status.idle":"2024-06-16T13:21:06.210598Z","shell.execute_reply.started":"2024-06-16T13:21:05.923622Z","shell.execute_reply":"2024-06-16T13:21:06.209715Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_nofull, val = train_test_split(df_nofull, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:06.212015Z","iopub.execute_input":"2024-06-16T13:21:06.212312Z","iopub.status.idle":"2024-06-16T13:21:06.219727Z","shell.execute_reply.started":"2024-06-16T13:21:06.212287Z","shell.execute_reply":"2024-06-16T13:21:06.218747Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_full = df.drop(val.index)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:06.222111Z","iopub.execute_input":"2024-06-16T13:21:06.222434Z","iopub.status.idle":"2024-06-16T13:21:06.232113Z","shell.execute_reply.started":"2024-06-16T13:21:06.222408Z","shell.execute_reply":"2024-06-16T13:21:06.231136Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokens_nofull = train_nofull.processed_text.str.split(' ').reset_index().processed_text\ntokens_val = val.processed_text.str.split(' ').reset_index().processed_text\ntokens_full = train_full.processed_text.str.split(' ').reset_index().processed_text; tokens_full","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:06.233190Z","iopub.execute_input":"2024-06-16T13:21:06.233447Z","iopub.status.idle":"2024-06-16T13:21:06.385772Z","shell.execute_reply.started":"2024-06-16T13:21:06.233424Z","shell.execute_reply":"2024-06-16T13:21:06.384719Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0       [аа, союзная, тридцать, пять, дробь, один, лар...\n1       [аа, приложение, мне, показывает, к, оплате, у...\n2       [а, что, добрый, день, NAME, у, меня, пришел, ...\n3       [у, меня, западный, с, утра, да, да, еще, да, ...\n4       [NAME, ну, а, по, поводу, ипотеки, по, моему, ...\n                              ...                        \n3343    [а, доброе, утро, меня, заинтересовала, ваш, п...\n3344    [здравствуйте, меня, зовут, иван, я, бы, хотел...\n3345    [целенаправлен, на, голосовой, почтовый, ящик,...\n3346    [NAME, зовут, NAME, я, хотела, уточнить, ээ, с...\n3347    [далее, здравствуйте, NAME, зовут, так, хотел,...\nName: processed_text, Length: 3348, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"dicts_full = train_full.target_labels_positions.apply(ast.literal_eval).reset_index().target_labels_positions\ndicts_val = val.target_labels_positions.apply(ast.literal_eval).reset_index().target_labels_positions\ndicts_nofull = train_nofull.target_labels_positions.apply(ast.literal_eval).reset_index().target_labels_positions","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:06.387241Z","iopub.execute_input":"2024-06-16T13:21:06.387882Z","iopub.status.idle":"2024-06-16T13:21:06.465526Z","shell.execute_reply.started":"2024-06-16T13:21:06.387848Z","shell.execute_reply":"2024-06-16T13:21:06.464583Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def create_tags(tokens, dicts):\n    tags = []\n    text_lengths = tokens.apply(len)\n\n    for length, labels in zip(text_lengths, dicts):\n        index_label = [(key, pos) for key, positions in labels.items() for pos in positions]\n        result = ['O'] * length\n        for i in index_label:\n            result[i[1]] = i[0]\n        tags.append(result)\n    return tags","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:07.303928Z","iopub.execute_input":"2024-06-16T13:21:07.304817Z","iopub.status.idle":"2024-06-16T13:21:07.311194Z","shell.execute_reply.started":"2024-06-16T13:21:07.304783Z","shell.execute_reply":"2024-06-16T13:21:07.310166Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"final_set_full = pd.DataFrame({'tokens': tokens_full.values, 'tags': create_tags(tokens_full, dicts_full)})\nfinal_set_nofull = pd.DataFrame({'tokens': tokens_nofull.values, 'tags': create_tags(tokens_nofull, dicts_nofull)})\nfinal_set_val = pd.DataFrame({'tokens': tokens_val.values, 'tags': create_tags(tokens_val, dicts_val)})","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:08.273804Z","iopub.execute_input":"2024-06-16T13:21:08.274387Z","iopub.status.idle":"2024-06-16T13:21:08.310989Z","shell.execute_reply.started":"2024-06-16T13:21:08.274346Z","shell.execute_reply":"2024-06-16T13:21:08.309848Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"final_set_full.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:09.392969Z","iopub.execute_input":"2024-06-16T13:21:09.393945Z","iopub.status.idle":"2024-06-16T13:21:09.422047Z","shell.execute_reply.started":"2024-06-16T13:21:09.393899Z","shell.execute_reply":"2024-06-16T13:21:09.421133Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                              tokens  \\\n0  [аа, союзная, тридцать, пять, дробь, один, лар...   \n1  [аа, приложение, мне, показывает, к, оплате, у...   \n2  [а, что, добрый, день, NAME, у, меня, пришел, ...   \n3  [у, меня, западный, с, утра, да, да, еще, да, ...   \n4  [NAME, ну, а, по, поводу, ипотеки, по, моему, ...   \n\n                                                tags  \n0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n2  [O, O, O, O, O, O, O, O, O, O, O, O, B-discoun...  \n3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[аа, союзная, тридцать, пять, дробь, один, лар...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[аа, приложение, мне, показывает, к, оплате, у...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[а, что, добрый, день, NAME, у, меня, пришел, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-discoun...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[у, меня, западный, с, утра, да, да, еще, да, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[NAME, ну, а, по, поводу, ипотеки, по, моему, ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"label_list = ['O', 'I-value', 'B-value', 'B-discount']\nlabel_list","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:10.209319Z","iopub.execute_input":"2024-06-16T13:21:10.209699Z","iopub.status.idle":"2024-06-16T13:21:10.216570Z","shell.execute_reply.started":"2024-06-16T13:21:10.209669Z","shell.execute_reply":"2024-06-16T13:21:10.215388Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['O', 'I-value', 'B-value', 'B-discount']"},"metadata":{}}]},{"cell_type":"code","source":"dataset_hf_full = datasets.DatasetDict(\n    {'train': datasets.Dataset.from_pandas(final_set_full),\n     'val': datasets.Dataset.from_pandas(final_set_val)}\n)\ndataset_hf_full","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:11.208026Z","iopub.execute_input":"2024-06-16T13:21:11.208800Z","iopub.status.idle":"2024-06-16T13:21:11.502540Z","shell.execute_reply.started":"2024-06-16T13:21:11.208765Z","shell.execute_reply":"2024-06-16T13:21:11.501501Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 3348\n    })\n    val: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 51\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_hf_nofull = datasets.DatasetDict(\n    {'train': datasets.Dataset.from_pandas(final_set_nofull),\n     'val': datasets.Dataset.from_pandas(final_set_val)}\n)\ndataset_hf_nofull","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:12.162843Z","iopub.execute_input":"2024-06-16T13:21:12.163253Z","iopub.status.idle":"2024-06-16T13:21:12.227398Z","shell.execute_reply.started":"2024-06-16T13:21:12.163220Z","shell.execute_reply":"2024-06-16T13:21:12.226426Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 452\n    })\n    val: Dataset({\n        features: ['tokens', 'tags'],\n        num_rows: 51\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('sergeyzh/rubert-mini-sts')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:13.143018Z","iopub.execute_input":"2024-06-16T13:21:13.143375Z","iopub.status.idle":"2024-06-16T13:21:13.859119Z","shell.execute_reply.started":"2024-06-16T13:21:13.143349Z","shell.execute_reply":"2024-06-16T13:21:13.858047Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26e808abea74e3698824feaf54d747a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/1.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae0ec8944a5b4d9996d69f3dc93a85e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb466bfd20242ec904563df37301c80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7158d022ec9b4397856df1e66fc64d81"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_and_align_labels(example, label_all_tokens = True):\n    tokenized_input = tokenizer(example['tokens'], truncation=True, is_split_into_words=True)\n    labels = []\n\n    for i, label in enumerate(example['tags']):\n        word_ids = tokenized_input.word_ids(batch_index=i) # returns a list indicating the word corresponding to each token\n        previous_word_idx = None\n\n        label_ids = []\n\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n            previous_word_idx = word_idx\n        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n        labels.append(label_ids)\n    tokenized_input['labels'] = labels\n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:14.623994Z","iopub.execute_input":"2024-06-16T13:21:14.624381Z","iopub.status.idle":"2024-06-16T13:21:14.637046Z","shell.execute_reply.started":"2024-06-16T13:21:14.624354Z","shell.execute_reply":"2024-06-16T13:21:14.635963Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tokenized_dataset_full = dataset_hf_full.map(tokenize_and_align_labels, batched=True)\ntokenized_dataset_nofull = dataset_hf_nofull.map(tokenize_and_align_labels, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:15.414899Z","iopub.execute_input":"2024-06-16T13:21:15.415278Z","iopub.status.idle":"2024-06-16T13:21:23.391673Z","shell.execute_reply.started":"2024-06-16T13:21:15.415249Z","shell.execute_reply":"2024-06-16T13:21:23.390740Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3348 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e4a9c1b84a456e9fe77afd26ec787e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15d0862064c84faf9d711102317de461"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/452 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adba5b8779a448c49036813e75655f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bd361ad01241d5b5287f276e1d2b90"}},"metadata":{}}]},{"cell_type":"code","source":"model_nofull = AutoModelForTokenClassification.from_pretrained('sergeyzh/rubert-mini-sts', num_labels=len(label_list))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:33.686666Z","iopub.execute_input":"2024-06-16T13:58:33.687057Z","iopub.status.idle":"2024-06-16T13:58:33.894461Z","shell.execute_reply.started":"2024-06-16T13:58:33.687031Z","shell.execute_reply":"2024-06-16T13:58:33.893480Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at sergeyzh/rubert-mini-sts and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_full = AutoModelForTokenClassification.from_pretrained('sergeyzh/rubert-mini-sts', num_labels=len(label_list))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:21:24.977794Z","iopub.execute_input":"2024-06-16T13:21:24.978520Z","iopub.status.idle":"2024-06-16T13:21:26.763940Z","shell.execute_reply.started":"2024-06-16T13:21:24.978482Z","shell.execute_reply":"2024-06-16T13:21:26.763013Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/692 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12c4f6481c99421fb23e18d3079a5436"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/130M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d6a4f0d45ab4f4a990027cc1a4db3e1"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at sergeyzh/rubert-mini-sts and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at sergeyzh/rubert-mini-sts and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments('test-ner',\n                         eval_strategy='epoch',\n                         learning_rate=0.00002,\n                         per_device_train_batch_size=16,\n                         per_device_eval_batch_size=16,\n                         num_train_epochs=20,\n                         weight_decay=0.01,\n                         logging_steps=15,\n                         report_to='none')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:37.012232Z","iopub.execute_input":"2024-06-16T13:58:37.012632Z","iopub.status.idle":"2024-06-16T13:58:37.046495Z","shell.execute_reply.started":"2024-06-16T13:58:37.012601Z","shell.execute_reply":"2024-06-16T13:58:37.045729Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer) # forms a batch","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:37.318066Z","iopub.execute_input":"2024-06-16T13:58:37.318410Z","iopub.status.idle":"2024-06-16T13:58:37.322788Z","shell.execute_reply.started":"2024-06-16T13:58:37.318383Z","shell.execute_reply":"2024-06-16T13:58:37.321816Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef compute_metrics(eval_preds):\n    pred_logits, labels = eval_preds\n\n    pred_logits = np.argmax(pred_logits, axis=2)\n\n    predictions = [\n        [label_list[prediction] for (prediction, label) in zip(pred, true_label) if label != -100]\n          for pred, true_label in zip(pred_logits, labels)\n    ]\n\n    true_labels = [\n        [label_list[label] for (prediction, label) in zip(pred, true_label) if label != -100]\n          for pred, true_label in zip(pred_logits, labels)\n    ]\n\n    class_weights = {'O': 0.003, 'B-discount': 1, 'B-value': 2, 'I-value': 2}\n    sample_weight = [[class_weights[label] for label in seq] for seq in true_labels]\n    sample_weight = [item for sublist in sample_weight for item in sublist]\n    \n    predictions_flat = [item for sublist in predictions for item in sublist]\n    true_labels_flat = [item for sublist in true_labels for item in sublist]\n    \n    results = f1_score(true_labels_flat, predictions_flat, average='weighted', sample_weight=sample_weight)\n    \n    return {\n        'f1_weighted': results\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:37.676077Z","iopub.execute_input":"2024-06-16T13:58:37.676430Z","iopub.status.idle":"2024-06-16T13:58:37.685826Z","shell.execute_reply.started":"2024-06-16T13:58:37.676402Z","shell.execute_reply":"2024-06-16T13:58:37.684888Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"trainer_nofull = Trainer(\n    model_nofull,\n    args,\n    train_dataset=tokenized_dataset_nofull['train'],\n    eval_dataset=tokenized_dataset_nofull['val'],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\ntrainer_full = Trainer(\n    model_full,\n    args,\n    train_dataset=tokenized_dataset_full['train'],\n    eval_dataset=tokenized_dataset_full['val'],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:38.631315Z","iopub.execute_input":"2024-06-16T13:58:38.631940Z","iopub.status.idle":"2024-06-16T13:58:38.692724Z","shell.execute_reply.started":"2024-06-16T13:58:38.631910Z","shell.execute_reply":"2024-06-16T13:58:38.691915Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-06-16T13:58:39.961313Z","iopub.execute_input":"2024-06-16T13:58:39.961713Z","iopub.status.idle":"2024-06-16T13:58:39.965877Z","shell.execute_reply.started":"2024-06-16T13:58:39.961684Z","shell.execute_reply":"2024-06-16T13:58:39.964846Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"trainer_nofull.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:00:39.792026Z","iopub.execute_input":"2024-06-16T14:00:39.792746Z","iopub.status.idle":"2024-06-16T14:02:36.682073Z","shell.execute_reply.started":"2024-06-16T14:00:39.792714Z","shell.execute_reply":"2024-06-16T14:02:36.681136Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 01:55, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.046300</td>\n      <td>0.031181</td>\n      <td>0.458103</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.042500</td>\n      <td>0.027774</td>\n      <td>0.395638</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.043300</td>\n      <td>0.028659</td>\n      <td>0.668197</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.041500</td>\n      <td>0.025402</td>\n      <td>0.511229</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.036600</td>\n      <td>0.026752</td>\n      <td>0.693501</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.034300</td>\n      <td>0.026515</td>\n      <td>0.696851</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.033000</td>\n      <td>0.025827</td>\n      <td>0.707180</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.032000</td>\n      <td>0.024822</td>\n      <td>0.721267</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.031500</td>\n      <td>0.025090</td>\n      <td>0.758632</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.036800</td>\n      <td>0.024330</td>\n      <td>0.740473</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.029300</td>\n      <td>0.023564</td>\n      <td>0.749509</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.028400</td>\n      <td>0.024542</td>\n      <td>0.786828</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.028300</td>\n      <td>0.023402</td>\n      <td>0.756470</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.026900</td>\n      <td>0.023353</td>\n      <td>0.762782</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.029800</td>\n      <td>0.024019</td>\n      <td>0.790406</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.027300</td>\n      <td>0.023026</td>\n      <td>0.769016</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.026700</td>\n      <td>0.023615</td>\n      <td>0.781261</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.026700</td>\n      <td>0.023367</td>\n      <td>0.775413</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.026500</td>\n      <td>0.023440</td>\n      <td>0.775384</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.027400</td>\n      <td>0.023444</td>\n      <td>0.775384</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=300, training_loss=0.03275359143813451, metrics={'train_runtime': 116.5211, 'train_samples_per_second': 77.582, 'train_steps_per_second': 2.575, 'total_flos': 158908353256128.0, 'train_loss': 0.03275359143813451, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer_full.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:03:17.983263Z","iopub.execute_input":"2024-06-16T14:03:17.984238Z","iopub.status.idle":"2024-06-16T14:16:21.807563Z","shell.execute_reply.started":"2024-06-16T14:03:17.984204Z","shell.execute_reply":"2024-06-16T14:16:21.806794Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2100/2100 13:02, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1 Weighted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.004600</td>\n      <td>0.024347</td>\n      <td>0.675254</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.004100</td>\n      <td>0.025317</td>\n      <td>0.672603</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.003700</td>\n      <td>0.027417</td>\n      <td>0.661704</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.004300</td>\n      <td>0.027187</td>\n      <td>0.697817</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.004900</td>\n      <td>0.027783</td>\n      <td>0.661646</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.002700</td>\n      <td>0.030229</td>\n      <td>0.675579</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.002300</td>\n      <td>0.028849</td>\n      <td>0.626709</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.003300</td>\n      <td>0.027549</td>\n      <td>0.689155</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.001900</td>\n      <td>0.029863</td>\n      <td>0.667666</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.002800</td>\n      <td>0.030356</td>\n      <td>0.642907</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.003400</td>\n      <td>0.031499</td>\n      <td>0.636349</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.004300</td>\n      <td>0.031216</td>\n      <td>0.711656</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.001900</td>\n      <td>0.031956</td>\n      <td>0.683517</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.003100</td>\n      <td>0.032104</td>\n      <td>0.675638</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.002000</td>\n      <td>0.031440</td>\n      <td>0.671857</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.001700</td>\n      <td>0.032396</td>\n      <td>0.638524</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.002900</td>\n      <td>0.032122</td>\n      <td>0.650626</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.002400</td>\n      <td>0.032035</td>\n      <td>0.667459</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.002700</td>\n      <td>0.032198</td>\n      <td>0.661084</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.003100</td>\n      <td>0.032331</td>\n      <td>0.673603</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2100, training_loss=0.0034187019678453604, metrics={'train_runtime': 783.4483, 'train_samples_per_second': 85.468, 'train_steps_per_second': 2.68, 'total_flos': 1186367982695616.0, 'train_loss': 0.0034187019678453604, 'epoch': 20.0})"},"metadata":{}}]},{"cell_type":"code","source":"#model_nofull.save_pretrained('ner_model_nofull')\nmodel_full.save_pretrained('ner_model_full')\n#tokenizer.save_pretrained('tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:28.797305Z","iopub.execute_input":"2024-06-16T14:16:28.798302Z","iopub.status.idle":"2024-06-16T14:16:29.198080Z","shell.execute_reply.started":"2024-06-16T14:16:28.798255Z","shell.execute_reply":"2024-06-16T14:16:29.197046Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"id2label = {\n    str(i): label for i, label in enumerate(label_list)\n}\n\nlabel2id = {\n    label: str(i) for i, label in enumerate(label_list)\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:30.104877Z","iopub.execute_input":"2024-06-16T14:16:30.105297Z","iopub.status.idle":"2024-06-16T14:16:30.110583Z","shell.execute_reply.started":"2024-06-16T14:16:30.105260Z","shell.execute_reply":"2024-06-16T14:16:30.109490Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"import json\nconfig_full = json.load(open('/kaggle/working/ner_model_full/config.json'))\nconfig_nofull = json.load(open('/kaggle/working/ner_model_nofull/config.json'))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:30.357454Z","iopub.execute_input":"2024-06-16T14:16:30.357839Z","iopub.status.idle":"2024-06-16T14:16:30.362990Z","shell.execute_reply.started":"2024-06-16T14:16:30.357812Z","shell.execute_reply":"2024-06-16T14:16:30.362135Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"config_full['id2label'] = id2label\nconfig_full['label2id'] = label2id\nconfig_nofull['id2label'] = id2label\nconfig_nofull['label2id'] = label2id\n\njson.dump(config_full, open('/kaggle/working/ner_model_full/config.json', 'w'))\njson.dump(config_nofull, open('/kaggle/working/ner_model_nofull/config.json', 'w'))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:30.558620Z","iopub.execute_input":"2024-06-16T14:16:30.559383Z","iopub.status.idle":"2024-06-16T14:16:30.565403Z","shell.execute_reply.started":"2024-06-16T14:16:30.559356Z","shell.execute_reply":"2024-06-16T14:16:30.564413Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"model_finetuned_full = AutoModelForTokenClassification.from_pretrained('/kaggle/working/ner_model_full')\nmodel_finetuned_nofull = AutoModelForTokenClassification.from_pretrained('/kaggle/working/ner_model_nofull')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:30.771708Z","iopub.execute_input":"2024-06-16T14:16:30.772252Z","iopub.status.idle":"2024-06-16T14:16:30.965721Z","shell.execute_reply.started":"2024-06-16T14:16:30.772226Z","shell.execute_reply":"2024-06-16T14:16:30.964660Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('/kaggle/working/tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:30.997121Z","iopub.execute_input":"2024-06-16T14:16:30.997451Z","iopub.status.idle":"2024-06-16T14:16:31.055081Z","shell.execute_reply.started":"2024-06-16T14:16:30.997423Z","shell.execute_reply":"2024-06-16T14:16:31.054142Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\nnlp_full = pipeline('ner', model=model_finetuned_full, tokenizer=tokenizer)\nnlp_nofull = pipeline('ner', model=model_finetuned_nofull, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:31.482611Z","iopub.execute_input":"2024-06-16T14:16:31.482932Z","iopub.status.idle":"2024-06-16T14:16:31.522792Z","shell.execute_reply.started":"2024-06-16T14:16:31.482907Z","shell.execute_reply":"2024-06-16T14:16:31.521933Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# Function to reconstruct words from subwords\ndef reconstruct_words(ner_results, tokenizer):\n    reconstructed_results = []\n    temp_word = \"\"\n    start_idx = None\n    end_idx = None\n    entity = None\n\n    for token in ner_results:\n        if token['word'].startswith(\"##\"):\n            temp_word += token['word'][2:]\n            end_idx = token['end']\n        else:\n            if temp_word:\n                reconstructed_results.append({'entity': entity, 'score': token['score'], 'word': temp_word, 'start': start_idx, 'end': end_idx})\n            temp_word = token['word']\n            start_idx = token['start']\n            end_idx = token['end']\n            entity = token['entity']\n\n    # Append the last token\n    if temp_word:\n        reconstructed_results.append({'entity': entity, 'score': token['score'], 'word': temp_word, 'start': start_idx, 'end': end_idx})\n    \n    return reconstructed_results\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:31.898891Z","iopub.execute_input":"2024-06-16T14:16:31.899273Z","iopub.status.idle":"2024-06-16T14:16:31.907308Z","shell.execute_reply.started":"2024-06-16T14:16:31.899245Z","shell.execute_reply":"2024-06-16T14:16:31.906146Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"pred2_full = nlp_full([' '.join(tokens) for tokens in dataset_hf_full['val']['tokens']]) # inefficient since we don't need the exact probabilities now\npred2_nofull = nlp_nofull([' '.join(tokens) for tokens in dataset_hf_nofull['val']['tokens']])","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:32.092749Z","iopub.execute_input":"2024-06-16T14:16:32.093142Z","iopub.status.idle":"2024-06-16T14:16:38.594198Z","shell.execute_reply.started":"2024-06-16T14:16:32.093086Z","shell.execute_reply":"2024-06-16T14:16:38.593080Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"def find_word_index_by_char_range(s, start_idx, end_idx):\n    words = s.split()\n    \n    current_char_pos = 0\n    \n    word_indices = []\n    \n    for i, word in enumerate(words):\n        word_start_pos = current_char_pos\n        word_end_pos = current_char_pos + len(word) - 1\n        \n        if word_start_pos <= end_idx and word_end_pos >= start_idx:\n            word_indices.append(i)\n            \n        current_char_pos += len(word) + 1\n    \n    return word_indices\n\ninitial_string = \"Find the word index by the character range in the initial string\"\nstart_index = 5\nend_index = 22\n\nprint(find_word_index_by_char_range(initial_string, start_index, end_index))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:38.596063Z","iopub.execute_input":"2024-06-16T14:16:38.596492Z","iopub.status.idle":"2024-06-16T14:16:38.604209Z","shell.execute_reply.started":"2024-06-16T14:16:38.596463Z","shell.execute_reply":"2024-06-16T14:16:38.603261Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[1, 2, 3, 4]\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_initial_index(prediction, initial_string):\n    sentence = ' '.join(initial_string)\n    entities = {}\n    for i in prediction:\n        for j in find_word_index_by_char_range(s=sentence, start_idx=i['start'], end_idx=i['end']):\n            entities[j] = i['entity']\n    return entities","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:38.605394Z","iopub.execute_input":"2024-06-16T14:16:38.605715Z","iopub.status.idle":"2024-06-16T14:16:38.612868Z","shell.execute_reply.started":"2024-06-16T14:16:38.605690Z","shell.execute_reply":"2024-06-16T14:16:38.611868Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"preds_final_full = []\npreds_final_nofull = []\n\nfor prediction, initial_string in zip(pred2_full, dataset_hf_full['val']['tokens']):\n    initial_indicies = preds_final_full.append(get_initial_index(prediction, initial_string))\nfor prediction, initial_string in zip(pred2_nofull, dataset_hf_nofull['val']['tokens']):\n    initial_indicies = preds_final_nofull.append(get_initial_index(prediction, initial_string))\n    \npreds_final_full[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:38.614988Z","iopub.execute_input":"2024-06-16T14:16:38.615338Z","iopub.status.idle":"2024-06-16T14:16:38.740738Z","shell.execute_reply.started":"2024-06-16T14:16:38.615313Z","shell.execute_reply":"2024-06-16T14:16:38.739750Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"[{},\n {116: 'B-discount',\n  442: 'B-discount',\n  443: 'B-value',\n  444: 'I-value',\n  450: 'B-discount'},\n {236: 'B-discount'},\n {306: 'B-discount', 309: 'B-value', 310: 'I-value'},\n {},\n {91: 'B-discount', 92: 'I-value', 93: 'B-value', 94: 'I-value'},\n {12: 'B-discount',\n  17: 'B-value',\n  18: 'I-value',\n  43: 'B-value',\n  56: 'B-value',\n  57: 'I-value',\n  72: 'B-discount',\n  93: 'B-value'},\n {14: 'B-discount', 18: 'B-value', 19: 'I-value'},\n {},\n {19: 'I-value',\n  20: 'B-discount',\n  21: 'B-value',\n  22: 'I-value',\n  47: 'B-discount',\n  48: 'B-value',\n  49: 'I-value',\n  61: 'I-value',\n  83: 'I-value',\n  84: 'B-discount',\n  235: 'B-discount',\n  236: 'B-value',\n  237: 'I-value',\n  257: 'I-value',\n  283: 'I-value'}]"},"metadata":{}}]},{"cell_type":"code","source":"preds_val_full = []\npreds_val_nofull = []\nfor prediction, tokens in zip(preds_final_full, dataset_hf_full['val']['tokens']):\n    result = ['O'] * len(tokens)\n    for key, entity in prediction.items():\n        result[key] = entity\n    preds_val_full.append(result)\nfor prediction, tokens in zip(preds_final_nofull, dataset_hf_nofull['val']['tokens']):\n    result = ['O'] * len(tokens)\n    for key, entity in prediction.items():\n        result[key] = entity\n    preds_val_nofull.append(result)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:38.741787Z","iopub.execute_input":"2024-06-16T14:16:38.742070Z","iopub.status.idle":"2024-06-16T14:16:38.796339Z","shell.execute_reply.started":"2024-06-16T14:16:38.742046Z","shell.execute_reply":"2024-06-16T14:16:38.795259Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"score_full = []\nscore_nofull = []\nclass_weights = {'O': 0.003, 'B-discount': 1, 'B-value': 2, 'I-value': 2}\nfor i in range(len(preds_val_full)):\n    sample_weight = [class_weights[label] for label in dataset_hf_full['val']['tags'][i]]\n    score_full.append(f1_score(dataset_hf_full['val']['tags'][i], preds_val_full[i][:len(dataset_hf_full['val']['tags'][i])], average='weighted', sample_weight=sample_weight))\n\nfor i in range(len(preds_val_nofull)):\n    sample_weight = [class_weights[label] for label in dataset_hf_nofull['val']['tags'][i]]\n    score_nofull.append(f1_score(dataset_hf_nofull['val']['tags'][i], preds_val_nofull[i][:len(dataset_hf_nofull['val']['tags'][i])], average='weighted', sample_weight=sample_weight))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:38.797679Z","iopub.execute_input":"2024-06-16T14:16:38.798043Z","iopub.status.idle":"2024-06-16T14:16:45.312712Z","shell.execute_reply.started":"2024-06-16T14:16:38.798009Z","shell.execute_reply":"2024-06-16T14:16:45.311912Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print(np.mean(score_full))\nprint(np.mean(score_nofull))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T14:16:45.313790Z","iopub.execute_input":"2024-06-16T14:16:45.314106Z","iopub.status.idle":"2024-06-16T14:16:45.320164Z","shell.execute_reply.started":"2024-06-16T14:16:45.314067Z","shell.execute_reply":"2024-06-16T14:16:45.319137Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"0.5790931112371377\n0.7770718375791306\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/samolet/gt_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:03:02.730409Z","iopub.execute_input":"2024-06-16T09:03:02.731024Z","iopub.status.idle":"2024-06-16T09:03:02.792151Z","shell.execute_reply.started":"2024-06-16T09:03:02.730989Z","shell.execute_reply":"2024-06-16T09:03:02.791026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred2 = nlp([' '.join(tokens) for tokens in dataset_hf['val']['tokens']]) # inefficient since we don't need the exact probabilities now","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_f = nlp(list(test['processed_text'].values))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:05:41.860076Z","iopub.execute_input":"2024-06-16T09:05:41.860437Z","iopub.status.idle":"2024-06-16T09:06:05.526489Z","shell.execute_reply.started":"2024-06-16T09:05:41.860405Z","shell.execute_reply":"2024-06-16T09:06:05.525654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(test['processed_text'].values)[14]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:09:00.505248Z","iopub.execute_input":"2024-06-16T09:09:00.505922Z","iopub.status.idle":"2024-06-16T09:09:00.512168Z","shell.execute_reply.started":"2024-06-16T09:09:00.505889Z","shell.execute_reply":"2024-06-16T09:09:00.511209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_final2 = []\nfor prediction, initial_string in zip(pred_f, test['processed_text'].str.split()):\n    initial_indicies = preds_final2.append(get_initial_index(prediction, initial_string))\n    \npreds_final2[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:18:41.555145Z","iopub.execute_input":"2024-06-16T09:18:41.555832Z","iopub.status.idle":"2024-06-16T09:18:41.700790Z","shell.execute_reply.started":"2024-06-16T09:18:41.555797Z","shell.execute_reply":"2024-06-16T09:18:41.699877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = []\nfor prediction, tokens in zip(preds_final2, test['processed_text'].str.split()):\n    result = ['O'] * len(tokens)\n    for key, entity in prediction.items():\n        result[key] = entity\n    preds_test.append(result)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:18:57.927128Z","iopub.execute_input":"2024-06-16T09:18:57.927492Z","iopub.status.idle":"2024-06-16T09:18:57.948795Z","shell.execute_reply.started":"2024-06-16T09:18:57.927462Z","shell.execute_reply":"2024-06-16T09:18:57.948029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(preds_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:21:39.556013Z","iopub.execute_input":"2024-06-16T09:21:39.556992Z","iopub.status.idle":"2024-06-16T09:21:39.563969Z","shell.execute_reply.started":"2024-06-16T09:21:39.556945Z","shell.execute_reply":"2024-06-16T09:21:39.562976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['label'] = preds_test","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:22:01.104708Z","iopub.execute_input":"2024-06-16T09:22:01.105582Z","iopub.status.idle":"2024-06-16T09:22:01.110427Z","shell.execute_reply.started":"2024-06-16T09:22:01.105548Z","shell.execute_reply":"2024-06-16T09:22:01.109368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('test_preds.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T09:24:09.377485Z","iopub.execute_input":"2024-06-16T09:24:09.377863Z","iopub.status.idle":"2024-06-16T09:24:09.446348Z","shell.execute_reply.started":"2024-06-16T09:24:09.377832Z","shell.execute_reply":"2024-06-16T09:24:09.445547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}